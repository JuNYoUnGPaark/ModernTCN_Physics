{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c37b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\park9\\AppData\\Local\\Temp\\ipykernel_39756\\235232063.py:225: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"subject_id\", group_keys=False).apply(_fill_subject_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split results (by sample count):\n",
      "  New Train set: 5441 samples\n",
      "  New Test set:  2332 samples\n",
      "\n",
      "\n",
      "============================================================\n",
      "üî¨ Ablation 1: Base (n_layers=3, Multi-scale, No SE)\n",
      "============================================================\n",
      "  - Parameters: 73,292\n",
      "[Model 1 (Base, L=3)] Epoch 25/50: Train Acc=99.50%, Test F1=0.9676, Test Acc=96.91% (Best F1: 0.9747, Best Acc: 97.64%)\n",
      "[Model 1 (Base, L=3)] Epoch 50/50: Train Acc=99.82%, Test F1=0.9728, Test Acc=97.47% (Best F1: 0.9775, Best Acc: 97.81%)\n",
      "\n",
      "============================================================\n",
      "üî¨ Ablation 2: + SE Block\n",
      "============================================================\n",
      "  - Parameters: 74,904\n",
      "[Model 2 (+SE)] Epoch 25/50: Train Acc=99.47%, Test F1=0.9748, Test Acc=97.81% (Best F1: 0.9799, Best Acc: 98.20%)\n",
      "[Model 2 (+SE)] Epoch 50/50: Train Acc=99.78%, Test F1=0.9774, Test Acc=98.07% (Best F1: 0.9810, Best Acc: 98.28%)\n",
      "\n",
      "============================================================\n",
      "üî¨ Ablation 3: + SE Block + Physics Loss\n",
      "============================================================\n",
      "  - Parameters: 77,083\n",
      "[Physics*] Epoch 025/50 | Train Acc=99.63% | CE=0.3159 | Phys=0.5195 (Œª_total=0.050) | Total=0.3419 || Test F1=0.9861 | Test Acc=98.76% (Best F1=0.9867, Best Acc=98.84%)\n",
      "[Physics*] Epoch 050/50 | Train Acc=99.83% | CE=0.3070 | Phys=0.5188 (Œª_total=0.050) | Total=0.3329 || Test F1=0.9865 | Test Acc=98.80% (Best F1=0.9874, Best Acc=98.89%)\n",
      "\n",
      "==========================================================================================\n",
      "Ablation Study ÏµúÏ¢Ö ÏöîÏïΩ (n_layers=3 Í∏∞Ï§Ä)\n",
      "==========================================================================================\n",
      "Model                               |              Best Test F1 |         Best Test Acc (%)\n",
      "-----------------------------------------------------------------------------------------\n",
      "1. Base (L=3, Multi)                |                    0.9775 |                     97.81\n",
      "2. + SE Block                       |                    0.9810 |                     98.28\n",
      "3. + Physics Loss                   |                    0.9874 |                     98.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import glob        \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from pathlib import Path\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt    \n",
    "from sklearn.metrics import f1_score    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ========================\n",
    "# SEED Í≥†Ï†ï Ìï®Ïàò\n",
    "# ========================\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # CUDA 11+\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.use_deterministic_algorithms(True, warn_only=False)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ========================\n",
    "# PAMAP2 Îç∞Ïù¥ÌÑ∞ Î°úÎìú \n",
    "# ========================\n",
    "def create_pamap2_windows(df: pd.DataFrame, window_size: int, step_size: int):\n",
    "    \"\"\"\n",
    "    subjectÎ≥ÑÎ°ú timestamp ÏàúÏÑúÎåÄÎ°ú Ï†ÑÏ≤¥ ÏãúÍ≥ÑÏó¥ÏùÑ Îî∞ÎùºÍ∞ÄÎ©∞ Ïä¨ÎùºÏù¥Îî© ÏúàÎèÑÏö∞ ÏÉùÏÑ±.\n",
    "    Ìïú ÏúàÎèÑÏö∞Ïùò ÎùºÎ≤®ÏùÄ ÎßàÏßÄÎßâ ÌîÑÎ†àÏûÑÏùò activityID.\n",
    "    ÎßàÏßÄÎßâ ÎùºÎ≤®Ïù¥ 0(Null/Í∏∞ÌÉÄ) Ïù¥Î©¥ Í∑∏ ÏúàÎèÑÏö∞Îäî Î≤ÑÎ¶∞Îã§.\n",
    "\n",
    "    Returns:\n",
    "        X:          (N, C, T) float32\n",
    "        y:          (N,) int64  (0..11Î°ú Î¶¨ÎßµÎêú Î†àÏù¥Î∏î)\n",
    "        subj_ids:   (N,) int64\n",
    "        label_names:list[str] Í∏∏Ïù¥ 12, new_index -> human-readable\n",
    "    \"\"\"\n",
    "\n",
    "    # ÏÇ¨Ïö©Ìï† ÌîºÏ≤òÎì§ (orientation*, heartrate, *_Temperature Îì±ÏùÄ Ï†úÏô∏)\n",
    "    feature_cols = [\n",
    "        # hand\n",
    "        \"handAcc16_1\",\"handAcc16_2\",\"handAcc16_3\",\n",
    "        \"handAcc6_1\",\"handAcc6_2\",\"handAcc6_3\",\n",
    "        \"handGyro1\",\"handGyro2\",\"handGyro3\",\n",
    "        \"handMagne1\",\"handMagne2\",\"handMagne3\",\n",
    "        # chest\n",
    "        \"chestAcc16_1\",\"chestAcc16_2\",\"chestAcc16_3\",\n",
    "        \"chestAcc6_1\",\"chestAcc6_2\",\"chestAcc6_3\",\n",
    "        \"chestGyro1\",\"chestGyro2\",\"chestGyro3\",\n",
    "        \"chestMagne1\",\"chestMagne2\",\"chestMagne3\",\n",
    "        # ankle\n",
    "        \"ankleAcc16_1\",\"ankleAcc16_2\",\"ankleAcc16_3\",\n",
    "        \"ankleAcc6_1\",\"ankleAcc6_2\",\"ankleAcc6_3\",\n",
    "        \"ankleGyro1\",\"ankleGyro2\",\"ankleGyro3\",\n",
    "        \"ankleMagne1\",\"ankleMagne2\",\"ankleMagne3\",\n",
    "    ]\n",
    "\n",
    "    # PAMAP2 Ïã§Ï†ú activityIDÎì§ Ï§ë Ïö∞Î¶¨Í∞Ä Ïì∞Îäî 12Í∞ú ÌÅ¥ÎûòÏä§Îßå ÎÇ®ÍπÄ\n",
    "    # ÏàúÏÑú Í≥†Ï†ï: Ïù¥ ÏàúÏÑúÍ∞Ä new class index 0..11Ïù¥ ÎêúÎã§.\n",
    "    ORDERED_IDS = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "\n",
    "    # ÏõêÎ≥∏ activityID -> new index(0..11)\n",
    "    old2new = {\n",
    "        1: 0,   # Lying\n",
    "        2: 1,   # Sitting\n",
    "        3: 2,   # Standing\n",
    "        4: 3,   # Walking\n",
    "        5: 4,   # Running\n",
    "        6: 5,   # Cycling\n",
    "        7: 6,   # Nordic walking\n",
    "        12: 7,  # Ascending stairs\n",
    "        13: 8,  # Descending stairs\n",
    "        16: 9,  # Vacuum cleaning\n",
    "        17: 10, # Ironing\n",
    "        24: 11, # Rope jumping\n",
    "    }\n",
    "\n",
    "    # new index -> ÏÇ¨ÎûåÏù¥ ÏùΩÎäî Ïù¥Î¶Ñ\n",
    "    label_names = [\n",
    "        \"Lying\",              # 0 -> orig 1\n",
    "        \"Sitting\",            # 1 -> orig 2\n",
    "        \"Standing\",           # 2 -> orig 3\n",
    "        \"Walking\",            # 3 -> orig 4\n",
    "        \"Running\",            # 4 -> orig 5\n",
    "        \"Cycling\",            # 5 -> orig 6\n",
    "        \"Nordic walking\",     # 6 -> orig 7\n",
    "        \"Ascending stairs\",   # 7 -> orig 12\n",
    "        \"Descending stairs\",  # 8 -> orig 13\n",
    "        \"Vacuum cleaning\",    # 9 -> orig 16\n",
    "        \"Ironing\",            # 10 -> orig 17\n",
    "        \"Rope jumping\",       # 11 -> orig 24\n",
    "    ]\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    subj_list = []\n",
    "\n",
    "    # subjectÎ≥ÑÎ°ú ÎÅäÏñ¥ÏÑú ÏãúÍ∞Ñ Ïàú Ï†ïÎ†¨ ÌõÑ Ïä¨ÎùºÏù¥Îî© ÏúàÎèÑÏö∞\n",
    "    for subj_id, g in df.groupby(\"subject_id\"):\n",
    "        # ÏãúÍ∞ÑÏàú Ï†ïÎ†¨\n",
    "        if \"timestamp\" in g.columns:\n",
    "            g = g.sort_values(\"timestamp\")\n",
    "        else:\n",
    "            g = g.sort_index()\n",
    "\n",
    "        data_arr  = g[feature_cols].to_numpy(dtype=np.float32)   # (L, C)\n",
    "        label_arr = g[\"activityID\"].to_numpy(dtype=np.int64)     # (L,)\n",
    "        L = data_arr.shape[0]\n",
    "\n",
    "        start = 0\n",
    "        while start + window_size <= L:\n",
    "            end = start + window_size\n",
    "\n",
    "            last_label_orig = int(label_arr[end - 1])\n",
    "\n",
    "            # 0 = \"other / null\" ‚Üí Î≤ÑÎ¶º\n",
    "            if last_label_orig == 0:\n",
    "                start += step_size\n",
    "                continue\n",
    "\n",
    "            # Ïö∞Î¶¨Í∞Ä Ïì∞Îäî 12Í∞ú ÌÅ¥ÎûòÏä§Ïóê ÏóÜÎäî ÎùºÎ≤®Ïù¥Î©¥ Î≤ÑÎ¶º\n",
    "            if last_label_orig not in old2new:\n",
    "                start += step_size\n",
    "                continue\n",
    "\n",
    "            # ÏúàÎèÑÏö∞ Ï∂îÏ∂ú\n",
    "            window_ct = data_arr[start:end].T  # (T, C) -> (C, T)\n",
    "\n",
    "            X_list.append(window_ct)\n",
    "            y_list.append(old2new[last_label_orig])\n",
    "            subj_list.append(int(subj_id))\n",
    "\n",
    "            start += step_size\n",
    "\n",
    "    # numpy Î≥ÄÌôò\n",
    "    X = np.stack(X_list, axis=0).astype(np.float32)      # (N, C, T)\n",
    "    y = np.asarray(y_list, dtype=np.int64)               # (N,)\n",
    "    subj_ids = np.asarray(subj_list, dtype=np.int64)     # (N,)\n",
    "\n",
    "    return X, y, subj_ids, label_names\n",
    "\n",
    "class PAMAP2Dataset(Dataset):\n",
    "    def __init__(self, data_dir, window_size, step_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) CSV Ï†ÑÎ∂Ä ÏùΩÏñ¥ÏÑú ÌïòÎÇòÏùò dfÎ°ú Ìï©ÏπòÍ∏∞\n",
    "        csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "        if len(csv_files) == 0:\n",
    "            raise RuntimeError(f\"No CSV files found under {data_dir}\")\n",
    "\n",
    "        dfs = []\n",
    "        for fpath in sorted(csv_files):\n",
    "            df_i = pd.read_csv(fpath)\n",
    "\n",
    "            if \"subject_id\" not in df_i.columns:\n",
    "                m = re.findall(r\"\\d+\", os.path.basename(fpath))\n",
    "                subj_guess = int(m[0]) if len(m) > 0 else 0\n",
    "                df_i[\"subject_id\"] = subj_guess\n",
    "\n",
    "            dfs.append(df_i)\n",
    "\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        df = df.dropna(subset=['activityID'])\n",
    "        \n",
    "        # Í∏∞Î≥∏ ÌÉÄÏûÖ Ï†ïÎ¶¨\n",
    "        df[\"activityID\"] = df[\"activityID\"].astype(np.int64)\n",
    "        df[\"subject_id\"] = df[\"subject_id\"].astype(np.int64)\n",
    "        if \"timestamp\" in df.columns:\n",
    "            df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "        # ===========================\n",
    "        # (1) NaN Ï≤òÎ¶¨\n",
    "        # ===========================\n",
    "        feature_cols = [\n",
    "            # hand\n",
    "            \"handAcc16_1\",\"handAcc16_2\",\"handAcc16_3\",\n",
    "            \"handAcc6_1\",\"handAcc6_2\",\"handAcc6_3\",\n",
    "            \"handGyro1\",\"handGyro2\",\"handGyro3\",\n",
    "            \"handMagne1\",\"handMagne2\",\"handMagne3\",\n",
    "            # chest\n",
    "            \"chestAcc16_1\",\"chestAcc16_2\",\"chestAcc16_3\",\n",
    "            \"chestAcc6_1\",\"chestAcc6_2\",\"chestAcc6_3\",\n",
    "            \"chestGyro1\",\"chestGyro2\",\"chestGyro3\",\n",
    "            \"chestMagne1\",\"chestMagne2\",\"chestMagne3\",\n",
    "            # ankle\n",
    "            \"ankleAcc16_1\",\"ankleAcc16_2\",\"ankleAcc16_3\",\n",
    "            \"ankleAcc6_1\",\"ankleAcc6_2\",\"ankleAcc6_3\",\n",
    "            \"ankleGyro1\",\"ankleGyro2\",\"ankleGyro3\",\n",
    "            \"ankleMagne1\",\"ankleMagne2\",\"ankleMagne3\",\n",
    "        ]\n",
    "\n",
    "        # subjectÎ≥ÑÎ°ú Í≤∞Ï∏°Ïπò Î≥¥Í∞Ñ -> ffill/bfillÎ°ú ÎßàÏ†Ä Î©îÏö∞Í∏∞\n",
    "        def _fill_subject_group(g):\n",
    "            # ÏãúÍ∞Ñ ÏàúÏúºÎ°ú Ï†ïÎ†¨ (timestamp ÏûàÏúºÎ©¥ timestamp Í∏∞Ï§Ä)\n",
    "            if \"timestamp\" in g.columns:\n",
    "                g = g.sort_values(\"timestamp\")\n",
    "            else:\n",
    "                g = g.sort_index()\n",
    "\n",
    "            # Í∞Å Ïª¨ÎüºÎ≥ÑÎ°ú interpolate + ffill/bfill\n",
    "            g[feature_cols] = (\n",
    "                g[feature_cols]\n",
    "                .interpolate(method=\"linear\", limit_direction=\"both\", axis=0)\n",
    "                .ffill()\n",
    "                .bfill()\n",
    "            )\n",
    "            return g\n",
    "\n",
    "        df = df.groupby(\"subject_id\", group_keys=False).apply(_fill_subject_group)\n",
    "\n",
    "        # Ïù¥ ÏãúÏ†êÏóêÏÑú feature_cols ÏïàÏóê NaNÏù¥ ÎÇ®ÏïÑÏûàÏúºÎ©¥ Ïïà Îê®\n",
    "        # ÌòπÏãúÎùºÎèÑ ÎÇ®ÏïòÏúºÎ©¥ 0ÏúºÎ°ú ÎßâÏïÑÎ≤ÑÎ¶¨Í∏∞ (safety net)\n",
    "        df[feature_cols] = df[feature_cols].fillna(0.0)\n",
    "\n",
    "        # ===========================\n",
    "        # (2) Ïä§ÏºÄÏùº ÌëúÏ§ÄÌôî \n",
    "        # ===========================\n",
    "        scaler = StandardScaler()\n",
    "        df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "        # ===========================\n",
    "        # (3) ÏúàÎèÑÏö∞ ÏÉùÏÑ±\n",
    "        # ===========================\n",
    "        X, y, subj_ids, label_names = create_pamap2_windows(\n",
    "            df,\n",
    "            window_size=window_size,\n",
    "            step_size=step_size,\n",
    "        )\n",
    "\n",
    "        self.X = X          # (N, C, T) float32\n",
    "        self.y = y          # (N,)\n",
    "        self.subject_ids = subj_ids\n",
    "        self.label_names = label_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.X[idx]).float(),\n",
    "            torch.tensor(self.y[idx], dtype=torch.long),\n",
    "            self.subject_ids[idx]\n",
    "        )\n",
    "    \n",
    "# ========================\n",
    "# üî• Modern TCN Components \n",
    "# ========================\n",
    "class DepthwiseSeparableConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(\n",
    "            in_channels, in_channels, kernel_size,\n",
    "            padding=padding, dilation=dilation, groups=in_channels\n",
    "        )\n",
    "        self.pointwise = nn.Conv1d(in_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class MultiScaleConvBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_sizes=[3, 5, 7], dilation=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList()\n",
    "        for k in kernel_sizes:\n",
    "            padding = ((k - 1) * dilation) // 2\n",
    "            branch = nn.ModuleDict({\n",
    "                'conv': DepthwiseSeparableConv1d(channels, channels, k, dilation, padding),\n",
    "                'norm': nn.BatchNorm1d(channels),\n",
    "                'dropout': nn.Dropout(dropout)\n",
    "            })\n",
    "            self.branches.append(branch)\n",
    "        self.fusion = nn.Conv1d(channels * len(kernel_sizes), channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        target_length = x.size(2)\n",
    "        for branch in self.branches:\n",
    "            out = branch['conv'](x)\n",
    "            if out.size(2) != target_length:\n",
    "                out = out[:, :, :target_length]\n",
    "            out = branch['norm'](out)\n",
    "            out = F.gelu(out)\n",
    "            out = branch['dropout'](out)\n",
    "            outputs.append(out)\n",
    "        multi_scale = torch.cat(outputs, dim=1)\n",
    "        return self.fusion(multi_scale)\n",
    "\n",
    "class ModernTCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 7], dilation=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # NOTE: kernel_sizesÍ∞Ä [7]Ï≤òÎüº Îã®Ïùº Î¶¨Ïä§Ìä∏Î°ú Îì§Ïñ¥Ïò§Î©¥ Single-scaleÏù¥ Îê®\n",
    "        self.multi_conv1 = MultiScaleConvBlock(\n",
    "            in_channels if in_channels == out_channels else out_channels,\n",
    "            kernel_sizes, dilation, dropout\n",
    "        )\n",
    "        \n",
    "        # NOTE: kernel_sizes Ï§ë Í∞ÄÏû• ÌÅ∞ Í∞íÏùÑ Í∏∞Ï§ÄÏúºÎ°ú padding\n",
    "        max_k = max(kernel_sizes) if isinstance(kernel_sizes, list) else kernel_sizes\n",
    "        padding = ((max_k - 1) * dilation) // 2\n",
    "        \n",
    "        self.conv2 = DepthwiseSeparableConv1d(\n",
    "            out_channels, out_channels, max_k, dilation, padding\n",
    "        )\n",
    "        self.norm2 = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        target_length = x.size(2)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "            residual = x\n",
    "        \n",
    "        out = self.multi_conv1(x)\n",
    "        if out.size(2) != target_length:\n",
    "            out = out[:, :, :target_length]\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        if out.size(2) != target_length:\n",
    "            out = out[:, :, :target_length]\n",
    "        out = self.norm2(out)\n",
    "        out = F.gelu(out)\n",
    "        out = self.dropout2(out)\n",
    "        return F.gelu(out + residual)\n",
    "\n",
    "class SqueezeExcitation1d(nn.Module):\n",
    "    def __init__(self, channels, reduction=5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "    def forward(self, x):\n",
    "        batch, channels, _ = x.size()\n",
    "        squeeze = F.adaptive_avg_pool1d(x, 1).view(batch, channels)\n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation)).view(batch, channels, 1)\n",
    "        return x * excitation\n",
    "\n",
    "class LargeKernelConv1d(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=21):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.depthwise = nn.Conv1d(\n",
    "            channels, channels, kernel_size,\n",
    "            padding=padding, groups=channels\n",
    "        )\n",
    "        self.norm = nn.BatchNorm1d(channels)\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.norm(out)\n",
    "        return out\n",
    "\n",
    "# ========================\n",
    "# Modern TCN Base Î™®Îç∏ \n",
    "# ========================\n",
    "class BaseModernTCNHAR(nn.Module):\n",
    "    def __init__(self, input_dim=9, hidden_dim=128, n_layers=4, n_classes=6,\n",
    "                 kernel_sizes=[3, 7], large_kernel=21, dropout=0.1, use_se=True):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv1d(input_dim, hidden_dim, 1)\n",
    "        self.large_kernel_conv = LargeKernelConv1d(hidden_dim, large_kernel)\n",
    "        self.tcn_blocks = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            dilation = 2 ** i\n",
    "            self.tcn_blocks.append(\n",
    "                ModernTCNBlock(\n",
    "                    hidden_dim, hidden_dim,\n",
    "                    kernel_sizes=kernel_sizes,\n",
    "                    dilation=dilation,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "            )\n",
    "        self.final_large_kernel = LargeKernelConv1d(hidden_dim, large_kernel)\n",
    "        # self.final_large_kernel = nn.Identity()\n",
    "        self.use_se = use_se\n",
    "        if use_se:\n",
    "            self.se = SqueezeExcitation1d(hidden_dim)\n",
    "        self.norm_final = nn.LayerNorm(hidden_dim)\n",
    "        self.head = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.large_kernel_conv(x)\n",
    "        x = F.gelu(x)\n",
    "        for block in self.tcn_blocks:\n",
    "            x = block(x)\n",
    "        x = self.final_large_kernel(x)\n",
    "        x = F.gelu(x)\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "        x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "        x = self.norm_final(x)\n",
    "        return self.head(x)\n",
    "\n",
    "# ========================\n",
    "# Physics-Guided Modern TCN HAR \n",
    "# ========================\n",
    "class PhysicsModernTCNHAR(BaseModernTCNHAR):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        hidden_dim = self.head.in_features\n",
    "\n",
    "        self.gravity_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_gravity=False):\n",
    "        x_feat = self.input_proj(x)\n",
    "        x_feat = F.gelu(self.large_kernel_conv(x_feat))\n",
    "        for block in self.tcn_blocks:\n",
    "            x_feat = block(x_feat)\n",
    "        x_feat = F.gelu(self.final_large_kernel(x_feat))\n",
    "        if self.use_se:\n",
    "            x_feat = self.se(x_feat)\n",
    "\n",
    "        pooled = F.adaptive_avg_pool1d(x_feat, 1).squeeze(-1)\n",
    "        pooled = self.norm_final(pooled)\n",
    "        logits = self.head(pooled)\n",
    "\n",
    "        outs = [logits]\n",
    "\n",
    "        if return_gravity:\n",
    "            seq_feat = x_feat.transpose(1, 2)  # (B,T,C)\n",
    "            gvec = self.gravity_head(seq_feat)   # (B,T,3)\n",
    "            outs.append(gvec)\n",
    "\n",
    "        return tuple(outs) if len(outs) > 1 else outs[0]\n",
    "\n",
    "# ========================\n",
    "# 'Î¨ºÎ¶¨ ÏÜêÏã§' Ìï®Ïàò \n",
    "# ========================\n",
    "def fir_lpf_hann_bt3(x, K=31):\n",
    "    \"\"\"\n",
    "    x: (B,T,3)  -> a_lp, a_hp (Îëò Îã§ (B,T,3))\n",
    "    Í∞ÑÎã® Hann Ï∞Ω ÌèâÍ∑† Í∏∞Î∞ò LPF. HPF = x - LPF\n",
    "    \"\"\"\n",
    "    assert x.dim() == 3 and x.size(-1) == 3\n",
    "    B, T, C = x.shape\n",
    "    xc = x.transpose(1, 2)  # (B,3,T)\n",
    "    w = torch.hann_window(K, dtype=xc.dtype, device=xc.device)\n",
    "    w = (w / w.sum()).view(1,1,-1).expand(C,1,-1)  # (3,1,K)\n",
    "    a_lp = F.conv1d(xc, w, padding=K//2, groups=C).transpose(1, 2)\n",
    "    a_hp = x - a_lp\n",
    "    return a_lp, a_hp\n",
    "\n",
    "def unit_norm(v, eps=1e-8):\n",
    "    return v / (v.norm(dim=-1, keepdim=True) + eps)\n",
    "\n",
    "def diff1(x):\n",
    "    # x: (B,T,D) -> same shape with zero-pad at t=0\n",
    "    d = x[:, 1:] - x[:, :-1]\n",
    "    pad = torch.zeros(x.size(0), 1, x.size(2), device=x.device, dtype=x.dtype)\n",
    "    return torch.cat([pad, d], dim=1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_dt_from_freq(default_dt=1/100):\n",
    "    # UCI-HAR‚âà50Hz, MHEALTH‚âà50Hz, WISDM‚âà20Hz, PAMAP2‚âà100Hz\n",
    "    return default_dt\n",
    "\n",
    "def physics_loss_upgraded(\n",
    "    X_raw,          # (B,T,9): [:,:,:3]=acc, [:,:,3:6]=gyro\n",
    "    g_pred,         # (B,T,3): gravity unit vector (Î™®Îç∏ ÏòàÏ∏°)\n",
    "    lambdas,        # dict: Í∞Å Ìï≠ Í∞ÄÏ§ëÏπò\n",
    "    params          # dict: ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞(tau_w,tau_a,alpha_lp,alpha_comp,win_mean,dt,g0)\n",
    "):\n",
    "    acc = X_raw[:, :, 12:15]  \n",
    "    gyro = X_raw[:, :, 18:21] \n",
    "    eps = 1e-8\n",
    "\n",
    "    # 1) LPFÎ°ú Ï§ëÎ†•ÌõÑÎ≥¥, HPFÎ°ú ÎèôÏ†ÅÏÑ±Î∂Ñ\n",
    "    a_lp, a_hp = fir_lpf_hann_bt3(acc, K=params.get('K', 31))\n",
    "    g_from_acc = unit_norm(a_lp, eps=eps)\n",
    "\n",
    "    # 2) Í≤åÏù¥ÌåÖ: Ï†ïÏ†Å/ÏôÑÎßå Íµ¨Í∞ÑÎßå Ïã†Î¢∞\n",
    "    tau_w = params.get('tau_w', 1.0)\n",
    "    tau_a = params.get('tau_a', 0.5)\n",
    "    gate = ((gyro.norm(dim=-1) < tau_w) & (a_hp.norm(dim=-1) < tau_a)).float()  # (B,T)\n",
    "\n",
    "    # 3) g_pred Ï†ïÍ∑úÌôî\n",
    "    g_pred = unit_norm(g_pred, eps=eps)\n",
    "\n",
    "    # 4) Í∞Å Ìï≠ Í≥ÑÏÇ∞\n",
    "    # (a) Î∞©Ìñ• Ï†ïÎ†¨ (LPF(acc)ÏôÄ Ï†ïÎ†¨)\n",
    "    cos_sim = (g_from_acc * g_pred).sum(dim=-1).clamp(-1+1e-6, 1-1e-6)\n",
    "    L_grav = torch.acos(cos_sim).mean()\n",
    "\n",
    "    # (b) Ï§ëÎ†• ÌÅ¨Í∏∞ (Ï†ïÍ∑úÌôîÎêú ÏûÖÎ†•Ïù¥Î©¥ g0‚âà1.0)\n",
    "    g0 = params.get('g0', 1.0)\n",
    "    L_gmag = (gate * (acc.norm(dim=-1) - g0).pow(2)).mean()\n",
    "\n",
    "    # (c) Î≥¥ÏôÑÌïÑÌÑ∞ ÏûîÏ∞®: g_comp vs g_pred\n",
    "    alpha_c = params.get('alpha_comp', 0.97)\n",
    "    dt = params.get('dt', estimate_dt_from_freq())\n",
    "    g_prev = torch.roll(g_pred, shifts=1, dims=1)\n",
    "    g_gyro = unit_norm(g_prev - dt * torch.cross(gyro, g_prev, dim=-1), eps=eps)\n",
    "    g_acc  = unit_norm(acc, eps=eps)\n",
    "    g_comp = unit_norm(alpha_c * g_gyro + (1 - alpha_c) * g_acc, eps=eps)\n",
    "    L_comp = torch.acos((g_comp * g_pred).sum(dim=-1).clamp(-1+1e-6, 1-1e-6)).mean()\n",
    "\n",
    "    # (d) ÏûêÏù¥Î°ú Î∞îÏù¥Ïñ¥Ïä§(Ï∞Ω ÌèâÍ∑†‚âà0) & (e) Ïä§Î¨¥Îî©(jerk/œâÃá)\n",
    "    win = params.get('win_mean', 16)\n",
    "    gyro_m = fir_lpf_hann_bt3(gyro, K=max(3, 2* (win//2)+1))[0]  # Ï∞Ω ÌèâÍ∑† ÎåÄÏö©\n",
    "    L_bias = (gate * gyro_m.pow(2).sum(dim=-1)).mean()\n",
    "    da = diff1(acc);  dw = diff1(gyro)\n",
    "    L_smooth = (da.pow(2).sum(dim=-1) + dw.pow(2).sum(dim=-1)).mean()\n",
    "\n",
    "    # (f) Î∂ÑÌï¥ ÏùºÍ¥ÄÏÑ±: a_total = a_body + g0*gÃÇ ‚Üí a_body Ï∞Ω ÌèâÍ∑†Ïù¥ 0 Í∑ºÏ≤ò\n",
    "    a_body = acc - g0 * g_pred\n",
    "    a_body_m = fir_lpf_hann_bt3(a_body, K=max(3, 2* (win//2)+1))[0]  # Î°úÏö∞Ìå®Ïä§=ÏúàÎèÑ ÌèâÍ∑†\n",
    "    L_split = a_body_m.norm(dim=-1).mean()\n",
    "\n",
    "    # (g) ÎØ∏Î∂ÑÏö¥ÎèôÌïô: dg/dt ‚âà -œâ√óg\n",
    "    dg = diff1(g_pred) / max(dt, 1e-3)\n",
    "    w_cross_g = torch.cross(gyro, g_pred, dim=-1)\n",
    "    L_pinn = (dg + w_cross_g).pow(2).sum(dim=-1).mean()\n",
    "\n",
    "    L = (\n",
    "        lambdas.get('grav', 0.10)   * L_grav  +\n",
    "        lambdas.get('gmag', 0.05)   * L_gmag  +\n",
    "        lambdas.get('comp', 0.10)   * L_comp  +\n",
    "        lambdas.get('bias', 0.02)   * L_bias  +\n",
    "        lambdas.get('smooth', 0.02) * L_smooth+\n",
    "        lambdas.get('split', 0.05)  * L_split +\n",
    "        lambdas.get('pinn', 0.03)   * L_pinn\n",
    "    )\n",
    "\n",
    "    stats = dict(grav=L_grav.item(), gmag=L_gmag.item(), comp=L_comp.item(),\n",
    "                 bias=L_bias.item(), smooth=L_smooth.item(),\n",
    "                 split=L_split.item(), pinn=L_pinn.item())\n",
    "    return L, stats\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Ìó¨Ìçº: ÌååÎùºÎØ∏ÌÑ∞ Ïπ¥Ïö¥Ìä∏\n",
    "# ========================\n",
    "def get_n_params(model):\n",
    "    return f\"{sum(p.numel() for p in model.parameters() if p.requires_grad):,}\"\n",
    "\n",
    "# ========================\n",
    "# 'Í∏∞Î≥∏' ÌïôÏäµ Ìï®Ïàò (F1 Score Í∏∞Ï§Ä)\n",
    "# ========================\n",
    "def train_base(model, train_loader, test_loader, device, n_classes, epochs, model_name=\"Base\"):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    best_f1 = 0.0\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # --- Í∏∞Î≥∏ ÌïôÏäµ (Physics Loss ÏóÜÏùå) ---\n",
    "            logits = model(X)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            # ------------------------------------\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        test_correct, test_total = 0, 0\n",
    "        all_preds = [] \n",
    "        all_y = []  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y, _ in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                \n",
    "                # --- Í∏∞Î≥∏ Ï∂îÎ°† ---\n",
    "                logits = model(X)\n",
    "                # -----------------\n",
    "                \n",
    "                preds = logits.argmax(1)\n",
    "\n",
    "                test_correct += (preds == y).sum().item() \n",
    "                test_total += y.size(0)           \n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_y.extend(y.cpu().numpy())\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        test_f1 = f1_score(all_y, all_preds, labels=list(range(n_classes)), average='macro', zero_division=0)\n",
    "        test_acc = 100 * test_correct / test_total\n",
    "\n",
    "        best_f1 = max(best_f1, test_f1) \n",
    "        best_acc = max(best_acc, test_acc)\n",
    "\n",
    "        if (epoch + 1) % 25 == 0 or epoch == epochs - 1:\n",
    "            print(f'[{model_name}] Epoch {epoch+1:02d}/{epochs}: Train Acc={train_acc:.2f}%, Test F1={test_f1:.4f}, Test Acc={test_acc:.2f}% (Best F1: {best_f1:.4f}, Best Acc: {best_acc:.2f}%)')\n",
    "\n",
    "    return best_f1, best_acc \n",
    "\n",
    "# ========================\n",
    "# 'Î¨ºÎ¶¨ Í∏∞Î∞ò' ÌïôÏäµ Ìï®Ïàò (F1 Score Í∏∞Ï§Ä)\n",
    "# ========================\n",
    "def train_physics(model, train_loader, test_loader, device, n_classes, epochs=50, lambda_phys=0.05, log_every=1):\n",
    "    \"\"\"\n",
    "    lambda_phys: Ï¥ù Î¨ºÎ¶¨ÏÜêÏã§ Ïä§ÏºÄÏùº (Í∞Å Ìï≠ ÏÉÅÎåÄÍ∞ÄÏ§ëÏπòÎäî ÎÇ¥Î∂Ä lambdas)\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "    # ÏÉÅÎåÄ Í∞ÄÏ§ëÏπò (Ïä§ÌÉÄÌåÖ Ìè¨Ïù∏Ìä∏)\n",
    "    base_lambdas = dict(grav=0.15, comp=0.15, split=0.10, gmag=0.03, bias=0.01, smooth=0.01, pinn=0.05)\n",
    "    # ÌïòÏù¥Ìçº (Îç∞Ïù¥ÌÑ∞ ÌëúÏ§ÄÌôî/Ï£ºÌååÏàòÏóê ÎßûÍ≤å Ï°∞Ï†ï)\n",
    "    params = dict(\n",
    "        tau_w=1.0, tau_a=0.5, alpha_comp=0.97,\n",
    "        win_mean=16, dt=estimate_dt_from_freq(), g0=1.0, K=31\n",
    "    )\n",
    "\n",
    "    best_f1 = best_acc = 0.0\n",
    "    history = {\"train_ce\": [], \"train_phys\": [], \"train_total\": [], \"test_acc\": [], \"test_f1\": []}\n",
    "\n",
    "    warm_epochs = 15\n",
    "    best_state = None\n",
    "    best_eval_cache = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        ce_sum = phys_sum = total_sum = 0.0\n",
    "        correct = total = 0\n",
    "\n",
    "        # warm-up Ïä§ÏºÄÏùº: Ï¥àÎ∞òÏóî Œª_physÎ•º ÏÑ†Ìòï Ï¶ùÍ∞Ä\n",
    "        if epoch <= warm_epochs:\n",
    "            phys_scale = lambda_phys * (epoch / warm_epochs)\n",
    "        else:\n",
    "            phys_scale = lambda_phys\n",
    "\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, gvec  = model(X, return_gravity=True)\n",
    "            loss_ce = F.cross_entropy(logits, y, label_smoothing=0.05)\n",
    "\n",
    "            L_phys, stats = physics_loss_upgraded(X.transpose(1, 2), g_pred=gvec, lambdas=base_lambdas, params=params)\n",
    "\n",
    "            loss = loss_ce + phys_scale * L_phys\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            ce_sum += loss_ce.item(); phys_sum += L_phys.item(); total_sum += loss.item()\n",
    "            preds = logits.argmax(1); correct += (preds == y).sum().item(); total += y.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        n_batches = len(train_loader)\n",
    "        ce_avg, phys_avg, total_avg = ce_sum/n_batches, phys_sum/n_batches, total_sum/n_batches\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # ===== ÌèâÍ∞Ä =====\n",
    "        model.eval()\n",
    "        test_correct = test_total = 0\n",
    "        all_preds, all_y = [], []\n",
    "        all_feats = []\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for X, y, _ in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                # ÌïôÏäµ Í≤ΩÎ°úÏôÄ ÎèôÏùºÌïòÍ≤å feature Ï∂îÏ∂ú ‚Üí pooled ÌôïÎ≥¥\n",
    "                feats = model.input_proj(X)\n",
    "                feats = model.large_kernel_conv(feats)\n",
    "                feats = F.gelu(feats)\n",
    "                for block in model.tcn_blocks:\n",
    "                    feats = block(feats)\n",
    "                feats = model.final_large_kernel(feats)\n",
    "                feats = F.gelu(feats)\n",
    "                if model.use_se:\n",
    "                    feats = model.se(feats)\n",
    "                pooled = F.adaptive_avg_pool1d(feats, 1).squeeze(-1)\n",
    "                pooled = model.norm_final(pooled)\n",
    "\n",
    "                logits = model.head(pooled)\n",
    "                preds = logits.argmax(1)\n",
    "\n",
    "                test_correct += (preds == y).sum().item()\n",
    "                test_total   += y.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_y.extend(y.cpu().numpy())\n",
    "                all_feats.append(pooled.cpu().numpy())   \n",
    "\n",
    "        test_acc = 100.0 * test_correct / test_total\n",
    "        test_f1 = f1_score(all_y, all_preds, labels=list(range(n_classes)), average='macro', zero_division=0)\n",
    "        best_acc = max(best_acc, test_acc)\n",
    "\n",
    "        if test_f1 > best_f1 + 1e-9:\n",
    "            best_f1 = test_f1\n",
    "            best_acc = max(best_acc, test_acc)\n",
    "            # CPU ÌÖêÏÑúÎ°ú ÍπäÏùÄ Î≥µÏÇ¨\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            # ‚úÖ Î≤†Ïä§Ìä∏ ÏãúÏ†ê Ï∫êÏãú Ï†ÄÏû•\n",
    "            best_eval_cache = {\n",
    "                \"y\":     np.array(all_y, dtype=np.int64),\n",
    "                \"preds\": np.array(all_preds, dtype=np.int64),\n",
    "                \"feats\": np.concatenate(all_feats, axis=0)  # (N, D)\n",
    "            }\n",
    "\n",
    "        history[\"train_ce\"].append(ce_avg); history[\"train_phys\"].append(phys_avg)\n",
    "        history[\"train_total\"].append(total_avg); history[\"test_acc\"].append(test_acc); history[\"test_f1\"].append(test_f1)\n",
    "\n",
    "        if (epoch % log_every) == 0:\n",
    "            print(f\"[Physics*] Epoch {epoch:03d}/{epochs} | Train Acc={train_acc:.2f}% | \"\n",
    "                  f\"CE={ce_avg:.4f} | Phys={phys_avg:.4f} (Œª_total={phys_scale:.3f}) | \"\n",
    "                  f\"Total={total_avg:.4f} || Test F1={test_f1:.4f} | Test Acc={test_acc:.2f}% \"\n",
    "                  f\"(Best F1={best_f1:.4f}, Best Acc={best_acc:.2f}%)\")\n",
    "\n",
    "    return best_f1, best_acc, history, best_state, best_eval_cache  \n",
    "\n",
    "\n",
    "# ========================\n",
    "# ÏãúÍ∞ÅÌôî Ìï®Ïàò\n",
    "# ========================\n",
    "def plot_results(results_dict):\n",
    "    print(\"\\n\" + \"=\"*90) # ‚≠êÔ∏è ÎÑàÎπÑ Ï°∞Ï†à\n",
    "    print(\"Ablation Study ÏµúÏ¢Ö ÏöîÏïΩ (n_layers=3 Í∏∞Ï§Ä)\")\n",
    "    print(\"=\"*90) # ‚≠êÔ∏è ÎÑàÎπÑ Ï°∞Ï†à\n",
    "    \n",
    "    print(f\"{'Model':<35} | {'Best Test F1':>25} | {'Best Test Acc (%)':>25}\")\n",
    "    print(\"-\" * 89) \n",
    "    \n",
    "    # ÎîïÏÖîÎÑàÎ¶¨ÏóêÏÑú F1Í≥º AccÎ•º Î™®Îëê Í∫ºÎÇ¥ÏÑú Ï∂úÎ†•\n",
    "    for name, metrics in results_dict.items():\n",
    "        print(f\"{name:<35} | {metrics['f1']:>25.4f} | {metrics['acc']:>25.2f}\")\n",
    "    print(\"-\" * 89)\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    # --- ÏãúÍ∞ÅÌôî (F1 Score Í∏∞Ï§Ä) ---\n",
    "    names = list(results_dict.keys())\n",
    "    scores_f1 = [metrics['f1'] for metrics in results_dict.values()]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5)) # Í∑∏ÎûòÌîÑ ÌÅ¨Í∏∞ Ï°∞Ï†à\n",
    "    colors = ['#AEC7E8', '#98DF8A', '#FF9896'] # 3Í∞ÄÏßÄ ÏÉâÏÉÅ\n",
    "    bars = plt.bar(names, scores_f1, color=colors)\n",
    "    plt.ylabel('Best F1 Score (Macro)', fontsize=12)\n",
    "    plt.title('Ablation Study: Component Contribution (Base n_layers=3)', fontsize=14)\n",
    "    plt.xticks(rotation=0, ha='center')\n",
    "    \n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.005, f'{yval:.4f}', \n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "    min_score = min(scores_f1) if scores_f1 else 0.9 # ÏµúÏÜåÍ∞í 0.9Î°ú Í∞ÄÏ†ï\n",
    "    plt.ylim(bottom=max(0, min_score - 0.02), top=max(scores_f1) * 1.02 if scores_f1 else 1.0) \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# ========================\n",
    "# Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò (Ablation Study)\n",
    "# ========================\n",
    "def main():\n",
    "    set_seed(42) \n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    data_path = 'C://Users/park9/ModernTCN_Physics/data' \n",
    "    window_size = 500  \n",
    "    step_size = 250    \n",
    "    N_CHANNELS = 36   \n",
    "    N_CLASSES = 12     \n",
    "    BATCH_SIZE = 64   \n",
    "    EPOCHS = 50     \n",
    "\n",
    "    try:\n",
    "        full_dataset = PAMAP2Dataset(data_path, window_size=window_size, step_size=step_size)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return\n",
    "    \n",
    "    N = len(full_dataset)\n",
    "    all_indices = np.arange(N)\n",
    "    \n",
    "    rng = np.random.default_rng(42)\n",
    "    rng.shuffle(all_indices)\n",
    "\n",
    "    n_train = int(0.7 * N)\n",
    "    train_idx = all_indices[:n_train]\n",
    "    test_idx  = all_indices[n_train:]\n",
    "\n",
    "    train_dataset = Subset(full_dataset, train_idx)\n",
    "    test_dataset  = Subset(full_dataset, test_idx)\n",
    "\n",
    "    print(f\"Split results (by sample count):\")\n",
    "    print(f\"  New Train set: {len(train_dataset)} samples\")\n",
    "    print(f\"  New Test set:  {len(test_dataset)} samples\\n\")\n",
    "\n",
    "\n",
    "    def compute_train_stats(train_subset):\n",
    "        # train_subset.indicesÎ•º ÏÇ¨Ïö©Ìï¥ ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú train ÏÉòÌîåÎßå Í∞ÄÏ†∏Ïò¥\n",
    "        X_train = torch.from_numpy(train_subset.dataset.X[train_subset.indices]).float()\n",
    "        mean = X_train.mean(dim=(0, 2), keepdim=False)\n",
    "        std  = X_train.std(dim=(0, 2), keepdim=False).clamp_min(1e-6)\n",
    "        return mean.view(1, -1, 1), std.view(1, -1, 1)\n",
    "\n",
    "    mean, std = compute_train_stats(train_dataset)\n",
    "\n",
    "    def collate_norm(batch):\n",
    "        X, y, s = zip(*batch)\n",
    "        X = torch.stack(X, dim=0).float()\n",
    "        X = (X - mean) / std\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        s = torch.tensor(s, dtype=torch.long)\n",
    "        return X, y, s\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(42)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        generator=g, num_workers=0, drop_last=True,\n",
    "        pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=0, drop_last=False,\n",
    "        pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "    )\n",
    "    \n",
    "    results = {} # Í≤∞Í≥º Ï†ÄÏû• ÎîïÏÖîÎÑàÎ¶¨\n",
    "\n",
    "    # ---\n",
    "    # üî¨ 1. New Base (n_layers=3, Multi-scale, No SE, No Physics)\n",
    "    # ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üî¨ Ablation 1: Base (n_layers=3, Multi-scale, No SE)\")\n",
    "    print(\"=\"*60)\n",
    "    set_seed(42)\n",
    "    model1 = BaseModernTCNHAR(\n",
    "        input_dim=N_CHANNELS, hidden_dim=64, n_layers=3, # ‚≠êÔ∏è n_layers=2\n",
    "        n_classes=N_CLASSES,\n",
    "        kernel_sizes=[3, 7], # ‚≠êÔ∏è Multi-scale Ïú†ÏßÄ\n",
    "        large_kernel=19, \n",
    "        dropout=0.4,\n",
    "        use_se=False         # ‚≠êÔ∏è SE OFF\n",
    "    ).to(device)\n",
    "    print(f\"  - Parameters: {get_n_params(model1)}\")\n",
    "    f1_1, acc_1 = train_base(model1, train_loader, test_loader, device, n_classes=N_CLASSES, epochs=EPOCHS, model_name=\"Model 1 (Base, L=3)\")\n",
    "    results['1. Base (L=3, Multi)'] = {'f1': f1_1, 'acc': acc_1}\n",
    "\n",
    "    # ---\n",
    "    # üî¨ 2. + SE Block\n",
    "    # ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üî¨ Ablation 2: + SE Block\")\n",
    "    print(\"=\"*60)\n",
    "    set_seed(42)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        generator=g, num_workers=0, drop_last=True,\n",
    "        pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=0, drop_last=False,\n",
    "        pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "    )\n",
    "    model2 = BaseModernTCNHAR(\n",
    "        input_dim=N_CHANNELS, hidden_dim=64, n_layers=3, # ‚≠êÔ∏è n_layers=2\n",
    "        n_classes=N_CLASSES,\n",
    "        kernel_sizes=[3, 7], # ‚≠êÔ∏è Multi-scale Ïú†ÏßÄ\n",
    "        large_kernel=19, \n",
    "        dropout=0.4,\n",
    "        use_se=True          # ‚≠êÔ∏è SE ON\n",
    "    ).to(device)\n",
    "    print(f\"  - Parameters: {get_n_params(model2)}\")\n",
    "    f1_2, acc_2 = train_base(model2, train_loader, test_loader, device, n_classes=N_CLASSES, epochs=EPOCHS, model_name=\"Model 2 (+SE)\")\n",
    "    results['2. + SE Block'] = {'f1': f1_2, 'acc': acc_2}\n",
    "    \n",
    "    # ---\n",
    "    # üî¨ 3. + Physics Loss (Full Model)\n",
    "    # ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üî¨ Ablation 3: + SE Block + Physics Loss\")\n",
    "    print(\"=\"*60)\n",
    "    set_seed(42)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=0, drop_last=True,\n",
    "        pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=0, drop_last=False,\n",
    "        pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "    )\n",
    "    model3 = PhysicsModernTCNHAR( # ‚≠êÔ∏è Physics Î™®Îç∏ ÏÇ¨Ïö©\n",
    "        input_dim=N_CHANNELS, hidden_dim=64, n_layers=3, # ‚≠êÔ∏è n_layers=2\n",
    "        n_classes=N_CLASSES,\n",
    "        kernel_sizes=[3, 7], # ‚≠êÔ∏è Multi-scale Ïú†ÏßÄ\n",
    "        large_kernel=19, \n",
    "        dropout=0.1,\n",
    "        use_se=True          # ‚≠êÔ∏è SE ON\n",
    "    ).to(device)\n",
    "    print(f\"  - Parameters: {get_n_params(model3)}\")\n",
    "    f1_3, acc_3, hist, best_state, best_eval = train_physics(model3, train_loader, test_loader, device,\n",
    "                                      n_classes=N_CLASSES, epochs=EPOCHS, lambda_phys=0.05, log_every=25) # ‚≠êÔ∏è train_physics ÏÇ¨Ïö©\n",
    "    results['3. + Physics Loss'] = {'f1': f1_3, 'acc': acc_3}\n",
    "\n",
    "    plot_results(results)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
